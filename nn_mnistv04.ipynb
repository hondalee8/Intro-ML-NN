{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nn_mnistv04.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN6qbnkz/M6XMayI9NmL8MG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"SPpuq1jdWqaV"},"source":["## **1.1 Building model and training model**"]},{"cell_type":"code","metadata":{"id":"NCvB-3gDWrIc"},"source":["import torch\n","from torchvision import transforms, datasets\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from matplotlib import pyplot as plt\n","\n","#import dataset\n","transform = transforms.ToTensor()\n","train_data = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n","test_data = datasets.MNIST(root='data', train=False, download=True, transform=transform)\n","print(\"number of image in train_data:{} | no. of image in test_data: {}\\n\".format(len(train_data), len(test_data)))\n","\n","#mini batch(each batch contain 60 images)\n","batch_size = 60 #each batch contain 60 images\n","trainset = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","testset = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n","\n","#define modle class\n","class MLP_Net (nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.l1 = nn.Linear(28*28, 520)\n","        self.l2 = nn.Linear(520, 320)\n","        self.l3 = nn.Linear(320, 240)\n","        self.l4 = nn.Linear(240, 120)\n","        self.l5 = nn.Linear(120, 10)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 784) #flatten the data from(n,1,28,28) -> (n, 784)\n","        x = F.relu(self.l1(x))\n","        x = F.relu(self.l2(x))\n","        x = F.relu(self.l3(x))\n","        x = F.relu(self.l4(x))\n","        x = self.l5(x)  \n","        return(x)\n","\n","#make an instance of the model\n","model = MLP_Net()\n","\n","# define loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n","\n","def training_loop(n_epoch):\n","    for epoch in range(n_epoch):\n","        for batch_idx, (data, target) in enumerate(trainset):\n","            optimizer.zero_grad()\n","            output = model(data)\n","            loss = criterion(output, target)\n","            loss.backward()\n","            optimizer.step()\n","            if batch_idx % 100 == 0:\n","              print('Train Epoch: {} | Batch_idx: {} | Batch Status: {}/{} ({:.0f}%) | Loss: {:.6f}'.format(\n","                    epoch, batch_idx,  batch_idx * len(data), len(train_data),\n","                    100. * batch_idx*len(data) / len(train_data), loss.item()))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n9GJhYBiWwEi"},"source":["## **1.2 Model training**"]},{"cell_type":"code","metadata":{"id":"2CKiU8XXWw7S"},"source":["#Model training\n","n_epoch =3\n","training_loop(n_epoch)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hh1VizzxW2x3"},"source":["## **1.3 Prediction base on trained model**"]},{"cell_type":"code","metadata":{"id":"0e-1DbqAW595"},"source":["i=1003\n","image = test_data[i][0]\n","\n","#do prediction:\n","p = model(image.view(-1, 28*28))\n","print(\"\\nPredict result is :\\n\", p)\n","print (\"\\nPredict value is {0}, Actual value is {1} : \".format(torch.argmax(p).data.numpy(), test_data[i][1] ))\n","plt.imshow(image.numpy()[0], cmap='gray') "],"execution_count":null,"outputs":[]}]}