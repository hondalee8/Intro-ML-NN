{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nn_mnistv03.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOeqaw8qPAlJ0V+pwJMq5Fb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"xZu_wx6erFCk"},"source":["# **Handwritten Digit Recognition(MNIST dataset) -- Intro Neural Network**"]},{"cell_type":"code","metadata":{"id":"gm2M4e6jrRmA"},"source":["import torch\n","from torchvision import transforms, datasets\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from matplotlib import pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q_RJq7MgrVIa"},"source":["## **Step 1: import data by dataloader in batch**\n","\n","\n","*   train_data = 60000 images\n","*   test_data = 10000 images\n"]},{"cell_type":"code","metadata":{"id":"nXmqUOyesN8q"},"source":["#import dataset\n","transform = transforms.ToTensor()\n","train_data = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n","test_data = datasets.MNIST(root='data', train=False, download=True, transform=transform)\n","print(\"number of image in train_data:{} | no. of image in test_data: {}\\n\".format(len(train_data), len(test_data)))\n","\n","#mini batch(each batch contain 60 images)\n","batch_size = 60 #each batch contain 60 images\n","trainset = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","testset = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y8v_vXnIscIa"},"source":["\n","## **Step 2: Knowning the dataset**"]},{"cell_type":"markdown","metadata":{"id":"sf4vylPQskgZ"},"source":["### How many image in each training batch?"]},{"cell_type":"code","metadata":{"id":"IZsSLtEEsr-I"},"source":["dataiter = iter(trainset)\n","images, labels = dataiter.next()\n","\n","print(images.shape)\n","print(labels.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6QFBLTkbsx2A"},"source":["Finding:\n","\n","There are 60 images in each batch, each image dimension is 28*28 pixels\n","\n","There are 60 labels in each batch"]},{"cell_type":"markdown","metadata":{"id":"1qmA6aIttUY0"},"source":["### Show the image in the training set"]},{"cell_type":"code","metadata":{"id":"GC7rxa5XtfEb"},"source":["plt.imshow(images[3].numpy().squeeze(), cmap='gray_r');"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M6FqLHb5Bzli"},"source":[" torch.set_printoptions(linewidth=300)\n"," print(images[3])\n"," "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s4hEPAPCtjXY"},"source":["figure = plt.figure()\n","num_of_images = 20\n","for index in range(1, num_of_images + 1):\n","    plt.subplot(5, 10, index)\n","    plt.axis('off')\n","    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nWGs0XaZtnuR"},"source":["## **Step 3: Build the Neural Network**"]},{"cell_type":"markdown","metadata":{"id":"YLpAgSu_tslJ"},"source":["### Define class for the model"]},{"cell_type":"code","metadata":{"id":"gZMCNp44tyyB"},"source":["#define modle class\n","class MLP_Net (nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.l1 = nn.Linear(28*28, 520)\n","        self.l2 = nn.Linear(520, 320)\n","        self.l3 = nn.Linear(320, 240)\n","        self.l4 = nn.Linear(240, 120)\n","        self.l5 = nn.Linear(120, 10)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 784) #flatten the data from(n,1,28,28) -> (n, 784)\n","        x = F.relu(self.l1(x))\n","        x = F.relu(self.l2(x))\n","        x = F.relu(self.l3(x))\n","        x = F.relu(self.l4(x))\n","        x = self.l5(x)  \n","        return(x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jR2zKclSt5QI"},"source":["### Define loss and optimizer function, by using pytorch API"]},{"cell_type":"code","metadata":{"id":"QOy8mqZ3t-A2"},"source":["model = MLP_Net()\n","\n","# define loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xBRkVqbfuByb"},"source":["### Define training loop"]},{"cell_type":"code","metadata":{"id":"Ovw4-ml3uK2J"},"source":["def training_loop(n_epoch):\n","    for epoch in range(n_epoch):\n","        for batch_idx, (data, target) in enumerate(trainset):\n","            #print(data.shape)\n","            optimizer.zero_grad()\n","            output = model(data)\n","            loss = criterion(output, target)\n","            loss.backward()\n","            optimizer.step()\n","            if batch_idx % 10 == 0:\n","                print('Train Epoch: {} | Batch_idx: {} | Batch Status: {}/{} ({:.0f}%) | Loss: {:.6f}'.format(\n","                    epoch, batch_idx,  batch_idx * len(data), len(train_data),\n","                    100. * batch_idx*len(data) / len(train_data), loss.item()))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DcIVdP1RuN-0"},"source":["## **Step 4: Train the model**"]},{"cell_type":"code","metadata":{"id":"2TBHNA8jubry"},"source":["n_epoch =3\n","training_loop(n_epoch)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QJkVlZLTuWhl"},"source":["## **Step 5: Predict value by using the trained model**"]},{"cell_type":"code","metadata":{"id":"9mvc4-VrukGz"},"source":["i=1003\n","\n","#image data\n","image = test_data[i][0]\n","\n","#do prediction:\n","p = model(image.view(-1, 28*28))\n","\n","print('\\npredict result is :\\n', p)\n","print ('\\npredict value is : ', torch.argmax(p))\n","print('\\nThe  label of of the image is: {} \\n'.format(test_data[i][1]))\n","plt.imshow(image.numpy()[0], cmap='gray')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M1RJGtREur2r"},"source":["## **Step 6: Calculate the Model Accuracy**"]},{"cell_type":"code","metadata":{"id":"9AaqW_EouzxP"},"source":["def cal_accuracy():\n","  total_count=0\n","  correct_count =0\n","  for image,label in test_data:\n","    p = model(image.view(-1, 28*28))\n","    pred_value = torch.argmax(p)\n","    if (pred_value == label):\n","      correct_count +=1 \n","    total_count+=1\n","  print(\"Total= {0}, Correct = {1}\".format(total_count, correct_count))\n","  print(\"Accuracy ={0}\".format(correct_count/total_count))\n","\n","cal_accuracy()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vSMRm-8ZOuCW"},"source":["## **Appendix 1: Whole code to the Model building and training**"]},{"cell_type":"markdown","metadata":{"id":"ZzXKWJ6IRWqk"},"source":["**Appendix 1.1 Building model and training model**"]},{"cell_type":"code","metadata":{"id":"vRydx0UZOz3F"},"source":["import torch\n","from torchvision import transforms, datasets\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from matplotlib import pyplot as plt\n","\n","#import dataset\n","transform = transforms.ToTensor()\n","train_data = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n","test_data = datasets.MNIST(root='data', train=False, download=True, transform=transform)\n","print(\"number of image in train_data:{} | no. of image in test_data: {}\\n\".format(len(train_data), len(test_data)))\n","\n","#mini batch(each batch contain 60 images)\n","batch_size = 60 #each batch contain 60 images\n","trainset = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","testset = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n","\n","#define modle class\n","class MLP_Net (nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.l1 = nn.Linear(28*28, 520)\n","        self.l2 = nn.Linear(520, 320)\n","        self.l3 = nn.Linear(320, 240)\n","        self.l4 = nn.Linear(240, 120)\n","        self.l5 = nn.Linear(120, 10)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 784) #flatten the data from(n,1,28,28) -> (n, 784)\n","        x = F.relu(self.l1(x))\n","        x = F.relu(self.l2(x))\n","        x = F.relu(self.l3(x))\n","        x = F.relu(self.l4(x))\n","        x = self.l5(x)  \n","        return(x)\n","\n","#make an instance of the model\n","model = MLP_Net()\n","\n","# define loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n","\n","def training_loop(n_epoch):\n","    for epoch in range(n_epoch):\n","        for batch_idx, (data, target) in enumerate(trainset):\n","            optimizer.zero_grad()\n","            output = model(data)\n","            loss = criterion(output, target)\n","            loss.backward()\n","            optimizer.step()\n","            if batch_idx % 100 == 0:\n","              print('Train Epoch: {} | Batch_idx: {} | Batch Status: {}/{} ({:.0f}%) | Loss: {:.6f}'.format(\n","                    epoch, batch_idx,  batch_idx * len(data), len(train_data),\n","                    100. * batch_idx*len(data) / len(train_data), loss.item()))\n","\n","\n","   "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0SsTuRNIetC1"},"source":["**Appendix 1.2 Model training**"]},{"cell_type":"code","metadata":{"id":"4DhdpUDZezai"},"source":["#Model training\n","n_epoch =3\n","training_loop(n_epoch)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1o5CO6MARhBc"},"source":["**Appendix 1.3 Prediction base on trained model**"]},{"cell_type":"code","metadata":{"id":"q8_rq84uRD11"},"source":["i=1003\n","image = test_data[i][0]\n","\n","#do prediction:\n","p = model(image.view(-1, 28*28))\n","print(\"\\nPredict result is :\\n\", p)\n","print (\"\\nPredict value is {0}, Actual value is {1} : \".format(torch.argmax(p).data.numpy(), test_data[i][1] ))\n","plt.imshow(image.numpy()[0], cmap='gray')                "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"skZF4Pxrvc_W"},"source":["ref: https://towardsdatascience.com/handwritten-digit-mnist-pytorch-977b5338e627"]}]}